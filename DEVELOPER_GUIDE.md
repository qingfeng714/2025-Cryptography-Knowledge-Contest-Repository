# å¼€å‘è€…æŒ‡å— - è·¨æ¨¡æ€éšç§å…³è”æ£€æµ‹ç³»ç»Ÿ

## ğŸ“š å¿«é€Ÿå¼€å§‹

### 1. ç³»ç»Ÿå¯åŠ¨
```bash
# Start Server
python app.py

# è®¿é—®å‰ç«¯
http://localhost:5000
```

### 2. æµ‹è¯•æ¥å£
```bash
# ä½¿ç”¨curlæµ‹è¯•CSVä¸Šä¼ 
curl -X POST http://localhost:5000/api/upload_csv \
  -F "csv_file=@test_medical_data.csv"

# æµ‹è¯•DICOMä¸Šä¼ 
curl -X POST http://localhost:5000/api/ingest \
  -F "dicom_file=@test_image.dcm"

# æµ‹è¯•æ£€æµ‹
curl -X POST http://localhost:5000/api/detect \
  -H "Content-Type: application/json" \
  -d '{"csv_id": "csv_abc123", "dicom_id": "ingest_xyz789"}'
```

---

## ğŸ”§ æ ¸å¿ƒä»£ç è§£æ

### 1. CSVå®ä½“æå–æ ¸å¿ƒé€»è¾‘

**ä½ç½®**: `services/crossmodal_service.py` â†’ `process_csv_detection()`

```python
# å®šä¹‰æ•æ„Ÿä¿¡æ¯åˆ—æ˜ å°„
sensitive_cols = {
    'Path': 'PATH',      # æ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«patient_id
    'Name': 'NAME',      # å§“å
    'Sex': 'SEX',        # æ€§åˆ«
    'Age': 'AGE',        # å¹´é¾„
    'Phone': 'PHONE',    # ç”µè¯
    'ID_Number': 'ID',   # èº«ä»½è¯å·
    'Address': 'ADDRESS' # åœ°å€
}

# æŒ‰åˆ—ç²¾ç¡®æå–
for idx, row in df.iterrows():
    for col_name, entity_type in sensitive_cols.items():
        if col_name in df.columns and pd.notna(row[col_name]):
            value = str(row[col_name]).strip()
            if value and value != '':
                entities.append({
                    'type': entity_type,
                    'text': value,
                    'confidence': 0.98,
                    'row_index': idx,      # CSVè¡Œå·
                    'column': col_name      # CSVåˆ—å
                })
```

**å…³é”®ç‚¹**:
- âœ… æŒ‰åˆ—åç›´æ¥æå–ï¼Œé¿å…æ­£åˆ™è¯¯åŒ¹é…
- âœ… è®°å½•è¡Œå·å’Œåˆ—åï¼Œä¾¿äºè¿½æº¯
- âœ… é«˜ç½®ä¿¡åº¦ï¼ˆ0.98ï¼‰å› ä¸ºæ˜¯ç»“æ„åŒ–æ•°æ®

---

### 2. Patient IDåŒ¹é…æ ¸å¿ƒé€»è¾‘

**ä½ç½®**: `services/crossmodal_service.py` â†’ `_match_text_dicom_entities()`

```python
# ä»Pathåˆ—æå–patient_id
if entity.get('column') == 'Path':
    import re
    match = re.search(r'patient(\d+)', entity_text)
    if match:
        csv_patient_id = 'patient' + match.group(1)  # ä¾‹å¦‚: patient00826
        dicom_patient_id = dicom_metadata.get('patient_id', '')
        
        if csv_patient_id == dicom_patient_id:
            # å®Œå…¨åŒ¹é… â†’ criticalé£é™©
            mappings.append({
                'csv_row': entity.get('row_index', 0),
                'csv_column': 'Path',
                'csv_value': entity_text,
                'extracted_patient_id': csv_patient_id,
                'dicom_field': 'patient_id',
                'dicom_value': dicom_patient_id,
                'match_type': 'patient_id_exact_match',
                'confidence': 1.0,
                'risk_level': 'critical'
            })
```

**åŒ¹é…è§„åˆ™**:
- Pathæ ¼å¼: `CheXpert-v1.0-small/train/patient00001/study1/view1_frontal.jpg`
- æ­£åˆ™æå–: `patient(\d+)` â†’ `patient00001`
- ä¸DICOMçš„PatientIDå­—æ®µå¯¹æ¯”

---

### 3. DICOM Headeræå–

**ä½ç½®**: `services/roi_service.py` â†’ `_extract_header_info()`

```python
PHI_TAGS = [
    'PatientID',              # (0010,0020)
    'PatientName',            # (0010,0010)
    'PatientBirthDate',       # (0010,0030)
    'PatientSex',             # (0010,0040)
    'PatientAge',             # (0010,1010)
    'InstitutionName',        # (0008,0080)
    'StudyDate',              # (0008,0020)
    'AccessionNumber',        # (0008,0050)
]

def _extract_header_info(self, ds) -> Dict[str, str]:
    info = {}
    for tag in PHI_TAGS:
        if hasattr(ds, tag):
            value = getattr(ds, tag)
            # è½¬æ¢DICOMæ•°æ®ç±»å‹
            if hasattr(value, 'decode'):
                value = value.decode('utf-8', errors='ignore')
            info[self._to_snake_case(tag)] = str(value)
    return info
```

---

### 4. å‰ç«¯-åç«¯æ•°æ®æµ

**å‰ç«¯ä¸Šä¼ ** (`templates/index.html`):
```javascript
async function handleSingleUpload() {
    const csvFile = document.getElementById('csvFile').files[0];
    const dicomFile = document.getElementById('dicomFile').files[0];
    
    // 1. ä¸Šä¼ CSV
    const csvFormData = new FormData();
    csvFormData.append('csv_file', csvFile);
    const csvResponse = await fetch('/api/upload_csv', {
        method: 'POST',
        body: csvFormData
    });
    const csvData = await csvResponse.json();
    
    // 2. ä¸Šä¼ DICOM
    const dicomFormData = new FormData();
    dicomFormData.append('dicom_file', dicomFile);
    const dicomResponse = await fetch('/api/ingest', {
        method: 'POST',
        body: dicomFormData
    });
    const dicomData = await dicomResponse.json();
    
    // 3. è°ƒç”¨æ£€æµ‹
    const detectResponse = await fetch('/api/detect', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({
            csv_id: csvData.file_id,
            dicom_id: dicomData.file_id
        })
    });
    const result = await detectResponse.json();
    
    // 4. æ˜¾ç¤ºç»“æœ
    displayResults(result);
}
```

**åç«¯å¤„ç†** (`app.py`):
```python
@app.route('/api/detect', methods=['POST'])
def detect():
    data = request.get_json()
    csv_id = data.get('csv_id')
    dicom_id = data.get('dicom_id')
    
    # è·å–æ–‡ä»¶è·¯å¾„
    csv_path = session_files.get(csv_id)
    dicom_path = session_files.get(dicom_id)
    
    # è°ƒç”¨æ£€æµ‹æœåŠ¡
    result = crossmodal_svc.process_csv_detection(
        csv_path=csv_path,
        dicom_path=dicom_path
    )
    
    return jsonify(result)
```

---

## ğŸ¨ å‰ç«¯å±•ç¤ºé€»è¾‘

### è·¨æ¨¡æ€å…³è”å¡ç‰‡ç”Ÿæˆ

**ä½ç½®**: `templates/index.html` â†’ `displayResults()`

```javascript
// æ ¹æ®åŒ¹é…ç±»å‹è®¾ç½®å›¾æ ‡å’Œé¢œè‰²
if (mapping.match_type === 'patient_id_exact_match') {
    icon = 'âœ…';
    title = 'Patient ID å®Œå…¨åŒ¹é…';
    // CSSç±»: .risk-item.critical (çº¢è‰²æ¸å˜)
} else if (mapping.match_type === 'name_match') {
    icon = 'ğŸ‘¤';
    title = 'å§“ååŒ¹é…';
    // CSSç±»: .risk-item.high (æ©™è‰²æ¸å˜)
}

// åŠ¨æ€ç”ŸæˆHTML
mappingDiv.innerHTML = `
    <div>${icon} ${title}</div>
    <div><strong>CSVä½ç½®:</strong> ç¬¬ <code>${mapping.csv_row}</code> è¡Œï¼Œ<code>${mapping.csv_column}</code> åˆ—</div>
    <div><strong>CSVå€¼:</strong> <code>${mapping.csv_value}</code></div>
    <div><strong>æå–çš„Patient ID:</strong> <code>${mapping.extracted_patient_id}</code></div>
    <div><strong>DICOMå­—æ®µ:</strong> <code>${mapping.dicom_field}</code> = <code>${mapping.dicom_value}</code></div>
    <div><strong>ç½®ä¿¡åº¦:</strong> ${(mapping.confidence * 100).toFixed(1)}%</div>
    <div><strong>è¯´æ˜:</strong> ${mapping.description}</div>
`;
```

---

## ğŸ“Š æ•°æ®ç»“æ„è¯¦è§£

### 1. å®ä½“å¯¹è±¡
```javascript
{
    "type": "NAME",           // å®ä½“ç±»å‹
    "text": "Jerry",          // å®ä½“æ–‡æœ¬
    "start": 0,               // èµ·å§‹ä½ç½®ï¼ˆä¸é‡è¦ï¼‰
    "end": 5,                 // ç»“æŸä½ç½®ï¼ˆä¸é‡è¦ï¼‰
    "confidence": 0.98,       // ç½®ä¿¡åº¦
    "row_index": 0,           // CSVè¡Œå· â­
    "column": "Name"          // CSVåˆ—å â­
}
```

### 2. åŒ¹é…å¯¹è±¡
```javascript
{
    "csv_row": 0,                          // CSVè¡Œå·
    "csv_column": "Path",                  // CSVåˆ—å
    "csv_value": "patient00826/...",       // CSVå€¼
    "extracted_patient_id": "patient00826", // æå–çš„ID â­
    "dicom_field": "patient_id",           // DICOMå­—æ®µå
    "dicom_value": "patient00826",         // DICOMå­—æ®µå€¼
    "match_type": "patient_id_exact_match", // åŒ¹é…ç±»å‹ â­
    "confidence": 1.0,                     // ç½®ä¿¡åº¦
    "risk_level": "critical",              // é£é™©çº§åˆ« â­
    "description": "CSV Pathä¸­çš„patient_idä¸DICOMå®Œå…¨åŒ¹é…" // è¯´æ˜
}
```

### 3. æ£€æµ‹ç»“æœå®Œæ•´å¯¹è±¡
```javascript
{
    "text_entities": [...],      // æ–‡æœ¬å®ä½“åˆ—è¡¨
    "image_regions": {           // å½±åƒåŒºåŸŸä¿¡æ¯
        "roi_mask": {...},
        "image_features": {...}
    },
    "mappings": [...],           // è·¨æ¨¡æ€åŒ¹é…åˆ—è¡¨ â­ æ ¸å¿ƒ
    "metrics": {                 // æ£€æµ‹æŒ‡æ ‡
        "total_entities": 7,
        "high_risk_count": 3,
        "mappings_found": 2,
        "f1_score": 0.92,
        "precision": 0.95,
        "recall": 0.89
    },
    "cross_modal_risks": [...]   // é£é™©è¯„ä¼°
}
```

---

## ğŸ”Œ æ‰©å±•ä¿æŠ¤å±‚æ¥å£

### æ¥å£å®šä¹‰
**æ–‡ä»¶**: `services/privacy_protection_interface.py`

```python
class PrivacyProtectionInterface:
    def request_protection(self, detection_result: Dict) -> Dict:
        """
        å°†æ£€æµ‹ç»“æœä¼ é€’ç»™ä¿æŠ¤å±‚
        
        ä¸‹æ¸¸éœ€è¦å®ç°çš„åŠŸèƒ½ï¼š
        1. ç­–ç•¥å†³ç­–ï¼šæ ¹æ®risk_levelé€‰æ‹©ä¿æŠ¤æ–¹å¼
        2. æ–‡æœ¬åŠ å¯†ï¼šå¯¹text_entitiesä¸­çš„æ•æ„Ÿä¿¡æ¯åŠ å¯†
        3. DICOMè„±æ•ï¼šåˆ é™¤/åŠ å¯†DICOM headerå­—æ®µ
        4. ç»“æœå­˜å‚¨ï¼šä¿å­˜å¤„ç†åçš„æ•°æ®
        """
        
        entities_to_protect = []
        dicom_fields_to_protect = []
        
        # ä»mappingsä¸­æå–éœ€è¦ä¿æŠ¤çš„å†…å®¹
        for mapping in detection_result.get('mappings', []):
            if mapping['risk_level'] in ['critical', 'high']:
                # æ ‡è®°éœ€è¦åŠ å¯†çš„DICOMå­—æ®µ
                dicom_fields_to_protect.append({
                    'field': mapping['dicom_field'],
                    'value': mapping['dicom_value'],
                    'action': 'encrypt'  # æˆ– 'remove'
                })
        
        # ä»text_entitiesä¸­æå–éœ€è¦ä¿æŠ¤çš„æ–‡æœ¬
        for entity in detection_result.get('text_entities', []):
            if entity['type'] in ['NAME', 'PHONE', 'ID', 'ADDRESS']:
                entities_to_protect.append({
                    'type': entity['type'],
                    'text': entity['text'],
                    'row': entity['row_index'],
                    'column': entity['column'],
                    'action': 'encrypt'  # æˆ– 'mask'
                })
        
        return {
            'text_entities': entities_to_protect,
            'dicom_fields': dicom_fields_to_protect,
            'risk_assessment': detection_result.get('metrics', {})
        }
```

### ä¸‹æ¸¸å®ç°ç¤ºä¾‹

```python
# ä¸‹æ¸¸å¼€å‘è€…éœ€è¦å®ç°çš„ç±»

class ProtectionLayer:
    def __init__(self):
        self.crypto = CryptoProcessor()
        self.policy = PolicyEngine()
    
    def process_detection_result(self, result: Dict):
        """å¤„ç†æ£€æµ‹ç»“æœ"""
        protection_config = PrivacyProtectionInterface().request_protection(result)
        
        # 1. åŠ å¯†æ–‡æœ¬å®ä½“
        for entity in protection_config['text_entities']:
            if entity['action'] == 'encrypt':
                encrypted = self.crypto.encrypt(entity['text'])
                # æ›´æ–°CSVæ–‡ä»¶
                self.update_csv(entity['row'], entity['column'], encrypted)
        
        # 2. å¤„ç†DICOMå­—æ®µ
        for field in protection_config['dicom_fields']:
            if field['action'] == 'encrypt':
                # åŠ å¯†DICOMå­—æ®µ
                self.crypto.encrypt_dicom_field(field['field'])
            elif field['action'] == 'remove':
                # åˆ é™¤DICOMå­—æ®µ
                self.remove_dicom_field(field['field'])
        
        # 3. ä¿å­˜å¤„ç†ç»“æœ
        self.save_protected_data()

class CryptoProcessor:
    def encrypt(self, text: str) -> str:
        """å®ç°åŠ å¯†ç®—æ³• (AES/SM4/FPEç­‰)"""
        pass
    
    def encrypt_dicom_field(self, field_name: str):
        """åŠ å¯†DICOMå­—æ®µ"""
        pass

class PolicyEngine:
    def get_policy(self, entity_type: str, risk_level: str) -> Dict:
        """
        æ ¹æ®å®ä½“ç±»å‹å’Œé£é™©çº§åˆ«è¿”å›ä¿æŠ¤ç­–ç•¥
        
        ç¤ºä¾‹ç­–ç•¥è¡¨:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Entity Type â”‚ Risk     â”‚ Action      â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ NAME        â”‚ critical â”‚ FPE encrypt â”‚
        â”‚ PHONE       â”‚ high     â”‚ AES encrypt â”‚
        â”‚ AGE         â”‚ medium   â”‚ Mask        â”‚
        â”‚ SEX         â”‚ low      â”‚ Keep        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        policies = {
            ('NAME', 'critical'): {'action': 'fpe_encrypt'},
            ('PHONE', 'high'): {'action': 'aes_encrypt'},
            ('AGE', 'medium'): {'action': 'mask'},
            ('SEX', 'low'): {'action': 'keep'}
        }
        return policies.get((entity_type, risk_level), {'action': 'remove'})
```

---

## ğŸ§ª æµ‹è¯•ç”¨ä¾‹

### 1. å•å…ƒæµ‹è¯•

**æµ‹è¯•NERæœåŠ¡**:
```python
# test_ner.py
from services.ner_service import NERService

def test_ner_detection():
    ner = NERService()
    text = "æ‚£è€…å¼ ä¸‰ï¼Œç”·ï¼Œ35å²ï¼Œç”µè¯13812345678"
    entities = ner.detect_from_text(text)
    
    assert len(entities) >= 3
    assert any(e['type'] == 'NAME' for e in entities)
    assert any(e['type'] == 'AGE' for e in entities)
    assert any(e['type'] == 'PHONE' for e in entities)
```

**æµ‹è¯•è·¨æ¨¡æ€åŒ¹é…**:
```python
# test_crossmodal.py
from services.crossmodal_service import CrossModalAttentionService

def test_patient_id_matching():
    svc = CrossModalAttentionService()
    
    entities = [
        {
            'type': 'PATH',
            'text': 'train/patient00826/study1/view1.jpg',
            'column': 'Path',
            'row_index': 0
        }
    ]
    
    dicom_metadata = {
        'patient_id': 'patient00826'
    }
    
    mappings = svc._match_text_dicom_entities(entities, dicom_metadata)
    
    assert len(mappings) == 1
    assert mappings[0]['match_type'] == 'patient_id_exact_match'
    assert mappings[0]['confidence'] == 1.0
```

### 2. é›†æˆæµ‹è¯•

```python
# test_integration.py
import requests

def test_full_workflow():
    base_url = "http://localhost:5000"
    
    # 1. ä¸Šä¼ CSV
    with open('test_data.csv', 'rb') as f:
        resp = requests.post(f'{base_url}/api/upload_csv', 
                            files={'csv_file': f})
        csv_id = resp.json()['file_id']
    
    # 2. ä¸Šä¼ DICOM
    with open('test_image.dcm', 'rb') as f:
        resp = requests.post(f'{base_url}/api/ingest',
                            files={'dicom_file': f})
        dicom_id = resp.json()['file_id']
    
    # 3. æ£€æµ‹
    resp = requests.post(f'{base_url}/api/detect',
                        json={'csv_id': csv_id, 'dicom_id': dicom_id})
    result = resp.json()
    
    # 4. éªŒè¯ç»“æœ
    assert 'text_entities' in result
    assert 'mappings' in result
    assert result['metrics']['f1_score'] >= 0.88
```

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### 1. CSVæ£€æµ‹ä¸åˆ°å®ä½“
**ç—‡çŠ¶**: `text_entities` ä¸ºç©ºæˆ–æ•°é‡ä¸å¯¹

**æ’æŸ¥æ­¥éª¤**:
```python
# åœ¨ crossmodal_service.py ä¸­æ·»åŠ è°ƒè¯•
print(f"CSVåˆ—å: {df.columns.tolist()}")
print(f"CSVè¡Œæ•°: {len(df)}")
print(f"ç¬¬ä¸€è¡Œæ•°æ®: {df.iloc[0].to_dict()}")
```

**å¸¸è§åŸå› **:
- âŒ CSVåˆ—åä¸åŒ¹é…ï¼ˆå¦‚ç”¨äº†å°å†™`name`è€Œä¸æ˜¯`Name`ï¼‰
- âŒ CSVä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯
- âŒ åˆ—å€¼ä¸ºç©ºï¼ˆ`NaN`ï¼‰

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä¿®æ”¹ sensitive_cols æ˜ å°„
sensitive_cols = {
    'Path': 'PATH',
    'Name': 'NAME',  # ç¡®ä¿å¤§å°å†™ä¸€è‡´
    'name': 'NAME',  # å…¼å®¹å°å†™
    # ...
}
```

### 2. è·¨æ¨¡æ€åŒ¹é…å¤±è´¥
**ç—‡çŠ¶**: `mappings` ä¸ºç©º

**æ’æŸ¥æ­¥éª¤**:
```python
# åœ¨ _match_text_dicom_entities ä¸­æ·»åŠ 
print(f"Entity column: {entity.get('column')}")
print(f"Entity text: {entity_text}")
print(f"DICOM patient_id: {dicom_metadata.get('patient_id')}")
```

**å¸¸è§åŸå› **:
- âŒ Pathæ ¼å¼ä¸åŒ¹é…ï¼ˆæ­£åˆ™æ— æ³•æå–patient_idï¼‰
- âŒ DICOMæœªæ­£ç¡®åŠ è½½ï¼Œmetadataä¸ºç©º
- âŒ patient_idæ ¼å¼ä¸ä¸€è‡´

**è§£å†³æ–¹æ¡ˆ**:
```python
# è°ƒæ•´æ­£åˆ™è¡¨è¾¾å¼
# åŸ: r'patient(\d+)'
# æ”¹: r'patient[_]?(\d+)'  # å…¼å®¹ patient_00826
```

### 3. DICOMè¯»å–å¤±è´¥
**ç—‡çŠ¶**: æ§åˆ¶å°æŠ¥é”™ `pydicom.errors.InvalidDicomError`

**åŸå› **: æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„DICOMæ ¼å¼

**è§£å†³æ–¹æ¡ˆ**:
```python
# åœ¨ roi_service.py ä¸­æ·»åŠ éªŒè¯
def process_dicom(self, dicom_path: Path, try_burnedin: bool = True):
    try:
        ds = pydicom.dcmread(str(dicom_path), force=True)
    except Exception as e:
        print(f"DICOMè¯»å–å¤±è´¥: {e}")
        return None
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡å¤„ç†ä¼˜åŒ–
```python
# ä½¿ç”¨å¤šè¿›ç¨‹
from multiprocessing import Pool

def process_batch_parallel(csv_files, dicom_files):
    with Pool(processes=4) as pool:
        results = pool.starmap(
            process_single_pair,
            zip(csv_files, dicom_files)
        )
    return results
```

### 2. ç¼“å­˜æœºåˆ¶
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_dicom_load(dicom_path: str):
    """ç¼“å­˜DICOMåŠ è½½ç»“æœ"""
    return pydicom.dcmread(dicom_path)
```

### 3. æ•°æ®åº“å­˜å‚¨
```python
# ä½¿ç”¨SQLiteå­˜å‚¨æ£€æµ‹ç»“æœ
import sqlite3

class ResultStore:
    def save_result(self, file_id: str, result: Dict):
        conn = sqlite3.connect('results.db')
        conn.execute(
            "INSERT INTO results VALUES (?, ?)",
            (file_id, json.dumps(result))
        )
        conn.commit()
```

---

## ğŸš€ éƒ¨ç½²æ£€æŸ¥æ¸…å•

### ç”Ÿäº§ç¯å¢ƒå‡†å¤‡
- [ ] ä½¿ç”¨ `gunicorn` æˆ– `uwsgi` æ›¿ä»£ Flask å¼€å‘æœåŠ¡å™¨
- [ ] é…ç½® Nginx åå‘ä»£ç†
- [ ] è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¸è¦ç¡¬ç¼–ç è·¯å¾„ï¼‰
- [ ] é…ç½®æ—¥å¿—è½®è½¬
- [ ] æ·»åŠ ç›‘æ§å’Œå‘Šè­¦
- [ ] è®¾ç½®æ–‡ä»¶ä¸Šä¼ å¤§å°é™åˆ¶
- [ ] é…ç½®CORSï¼ˆå¦‚æœéœ€è¦è·¨åŸŸï¼‰
- [ ] å¯ç”¨HTTPS

### å®‰å…¨æ£€æŸ¥
- [ ] éªŒè¯ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ç±»å‹
- [ ] é™åˆ¶æ–‡ä»¶å¤§å°
- [ ] æ·»åŠ è¯·æ±‚é¢‘ç‡é™åˆ¶
- [ ] æ¸…ç†ä¸´æ—¶æ–‡ä»¶
- [ ] ä¸è¦åœ¨æ—¥å¿—ä¸­è¾“å‡ºæ•æ„Ÿä¿¡æ¯
- [ ] ä½¿ç”¨å®‰å…¨çš„éšæœºæ•°ç”Ÿæˆå™¨

---

## ğŸ“ ä»£ç è§„èŒƒ

### Pythonä»£ç é£æ ¼
```python
# éµå¾ª PEP 8
# ä½¿ç”¨ç±»å‹æç¤º
def process_csv(csv_path: str, encoding: str = 'utf-8') -> pd.DataFrame:
    """
    å¤„ç†CSVæ–‡ä»¶
    
    Args:
        csv_path: CSVæ–‡ä»¶è·¯å¾„
        encoding: æ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤utf-8
        
    Returns:
        pd.DataFrame: å¤„ç†åçš„æ•°æ®æ¡†
        
    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
    """
    pass

# ä½¿ç”¨æœ‰æ„ä¹‰çš„å˜é‡å
patient_id = extract_id(text)  # âœ…
pid = get_id(t)  # âŒ
```

### æäº¤è§„èŒƒ
```bash
# ä½¿ç”¨è¯­ä¹‰åŒ–æäº¤æ¶ˆæ¯
git commit -m "feat: æ·»åŠ patient_idè·¨æ¨¡æ€åŒ¹é…åŠŸèƒ½"
git commit -m "fix: ä¿®å¤CSVåˆ—åå¤§å°å†™æ•æ„Ÿé—®é¢˜"
git commit -m "docs: æ›´æ–°APIæ–‡æ¡£"
git commit -m "refactor: é‡æ„NERæœåŠ¡ä»£ç ç»“æ„"
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### é—®é¢˜åé¦ˆ
- æäº¤ Issue åˆ°ä»“åº“
- é™„ä¸Šé”™è¯¯æ—¥å¿—å’Œå¤ç°æ­¥éª¤
- è¯´æ˜ç¯å¢ƒä¿¡æ¯ï¼ˆPythonç‰ˆæœ¬ã€OSç­‰ï¼‰

### è´¡çŒ®ä»£ç 
1. Fork ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ `git checkout -b feature/your-feature`
3. æäº¤æ›´æ”¹ `git commit -am 'Add some feature'`
4. æ¨é€åˆ†æ”¯ `git push origin feature/your-feature`
5. åˆ›å»º Pull Request

---

**æœ€åæ›´æ–°**: 2025-10-23  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0

